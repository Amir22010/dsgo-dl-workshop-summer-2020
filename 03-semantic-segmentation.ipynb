{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Semantic Segementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /home/stephen/anaconda3/envs/dsgo-cv/lib/python3.7/site-packages (3.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wget #For colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, argparse, zipfile, tarfile, sys\n",
    "from pathlib import Path\n",
    "\n",
    "def simple_progress_bar(current, total, width=80):\n",
    "    progress_message = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n",
    "    sys.stdout.write(\"\\r\" + progress_message); sys.stdout.flush()\n",
    "\n",
    "def get_and_unpack(url, location='data/'):\n",
    "    Path(location).mkdir(exist_ok=True)\n",
    "    filename = wget.download(url, out=location, bar=simple_progress_bar)\n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall(path=location)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 66% [60432384 / 90591239] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_and_unpack(url='http://www.welchlabs.io/unccv/deep_learning/bbc_train.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- But wait, there's more! \n",
    "- Let's explore one more type of problem we can solve using a very similar architecture: **semantic segmentation**. \n",
    "- Our goal in semantic segmentation is to assign each pixel to a specific class. \n",
    "- Now is a good time to start thinking about what type of dimension we need for the output of our nueral network in order to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from fastai.vision import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path=Path('data/bbc_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fnames = get_image_files(path/'images')\n",
    "fnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lbl_names = get_image_files(path/'masks')\n",
    "lbl_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_f = fnames[0]\n",
    "img = open_image(img_f)\n",
    "img.show(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_y_fn(x): return path/'masks'/(x.stem + '.png')\n",
    "classes = array(['background', 'brick', 'ball', 'cylinder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask = open_mask(get_y_fn(img_f))\n",
    "mask.show(figsize=(5,5), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique(mask.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src = (SegmentationItemList.from_folder(path/'images')\n",
    "       .split_by_rand_pct(0.2)\n",
    "       .label_from_func(get_y_fn, classes=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = (src.transform(get_transforms(), tfm_y=True, size=(256,256))\n",
    "        .databunch(bs=16)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.show_batch(3, figsize=(6,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Now, as you may have guessed we need to implement another custom head. \n",
    "- However, this time we need a slightly more complicated architecture for this portion of our network. \n",
    "- The challenge here is that we need to **upsample**, or make our tensors larger as they pass through the network. \n",
    "- We can achieve this using a special operation called a **transposed convoulation** - we'll dig more into the details of this operation later. \n",
    "- The thing to know for knwo is that transposed convulutional layers in our neural network allow us to learn an \"upsampling\" or mapping form smaller to larger tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv_trans(ni, nf, ks = 4, stride = 2, padding = 1):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding = padding), \n",
    "        nn.ReLU(inplace = True), \n",
    "        nn.BatchNorm2d(nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "custom_head=nn.Sequential(conv_trans(512, 256), \n",
    "                          conv_trans(256, 128),\n",
    "                          conv_trans(128, 64),\n",
    "                          conv_trans(64, 32), \n",
    "                          nn.ConvTranspose2d(32, 4, kernel_size=4, bias=False, stride=2, padding = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- We need to intorduce a slightly specialized performance measure here, the accuracy evaluate pixel by pixel (like we're solving a classification problem for each pixel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pixel_accuracy(yhat, y):\n",
    "    y_=y.squeeze(dim=1)\n",
    "    yhat_=yhat.argmax(dim=1)\n",
    "    return (y_==yhat_).sum().float()/y.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn=cnn_learner(data, models.resnet18, custom_head=custom_head, metrics=pixel_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr=1e-2\n",
    "learn.fit_one_cycle(4, slice(lr/10, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "learn.fit_one_cycle(8, slice(lr/10, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('basic-segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def blend_image_mask(im, mask, alpha=0.7):\n",
    "    im_mask=np.zeros((im.shape[1], im.shape[2], 3), dtype='float32')\n",
    "    for j in range(3): im_mask[:,:,j]=im.mean(axis=0)\n",
    "    for j in range(1, 4):\n",
    "        im_mask[mask==j] = alpha*im_mask[mask==j] + (1-alpha)*np.array([float(i==(j-1)) for i in range(3)])\n",
    "    return im_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_legend():\n",
    "    custom_lines = [Line2D([0], [0], color='r', lw=2, alpha=0.5),\n",
    "                    Line2D([0], [0], color='g', lw=2, alpha=0.5),\n",
    "                    Line2D([0], [0], color='b', lw=2, alpha=0.5)]\n",
    "\n",
    "    legend(custom_lines, ['Brick', 'Ball', 'Cylinder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "denorm=learn.data.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x,y = next(iter(learn.data.valid_dl))\n",
    "    yhat = to_np(learn.model(x))\n",
    "    x=denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x.shape, y.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yhat=yhat.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig=figure(0, (20, 10))\n",
    "\n",
    "for i in range(8):\n",
    "    fig.add_subplot(2,4,i+1)\n",
    "    im_mask=blend_image_mask(to_np(x[i]), yhat[i])\n",
    "    imshow(im_mask); axis('off'); make_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('/home/bbc-semantic-segmentation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
